{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0ef22a-00c4-4aec-801d-93fe4ebf1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df_parla = pl.read_parquet(\"./ParlaMind.parquet\")\n",
    "\n",
    "df_parla = df_parla.filter(pl.col(\"speechContent\").is_null() == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f22706-e730-4012-8671-ae1bb3fe8474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98611d-28d0-45de-b48b-aa86b32e6516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aab7cfc-2575-4d9a-9d87-498e2e8ea957",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m SentimentModel()\n\u001b[1;32m      7\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mde_core_news_lg\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtagger\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/spacy/compat.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcPickle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/thinc/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/thinc/config.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatalogue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Decorator\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/confection/__init__.py:35\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorType\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     Any,\n\u001b[1;32m     22\u001b[0m     Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     cast,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Extra, ValidationError, create_model\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/srsly/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_jsonl, write_jsonl\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m json_dumps, json_loads, is_json_serializable\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_msgpack_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_msgpack, write_msgpack, msgpack_dumps, msgpack_loads\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_msgpack_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m msgpack_encoders, msgpack_decoders\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pickle_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pickle_dumps, pickle_loads\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/srsly/_msgpack_api.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m msgpack\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsgpack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m msgpack_encoders, msgpack_decoders  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m force_path, FilePath, JSONInputBin, JSONOutputBin\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/srsly/msgpack/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_unpacker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpacker \u001b[38;5;28;01mas\u001b[39;00m _Unpacker\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtType\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_msgpack_numpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m encode_numpy \u001b[38;5;28;01mas\u001b[39;00m _encode_numpy\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_msgpack_numpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decode_numpy \u001b[38;5;28;01mas\u001b[39;00m _decode_numpy\n\u001b[1;32m     22\u001b[0m msgpack_encoders \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrsly\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsgpack_encoders\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/srsly/msgpack/_msgpack_numpy.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m     has_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     has_cupy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/textanal/lib/python3.12/site-packages/cupy/__init__.py:677\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_padding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpad\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Sorting, searching, and counting\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sorting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcount\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m count_nonzero  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sorting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m argmax  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sorting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m argmin  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1191\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from germansentiment import SentimentModel\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "model = SentimentModel()\n",
    "nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"tagger\"])\n",
    "\n",
    "batch_size = 512\n",
    "data_num = df_parla.height\n",
    "\n",
    "pos_results, neg_results, neut_results, major_class, sentiment_per_sentence = [], [], [], [], []\n",
    "\n",
    "for start_batch in tqdm(range(0, data_num, batch_size), desc=\"Processing Batches\"):\n",
    "    df_batch = df_parla.slice(start_batch, batch_size)\n",
    "\n",
    "    speeches_batch = df_batch[\"speechContent\"].to_list()\n",
    "    \n",
    "    result = model.predict_sentiment(speeches_batch, output_probabilities=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    '''\n",
    "    sentences_speeches = []\n",
    "    for speech in speeches_batch:    \n",
    "        doc = nlp(speech)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "        for sentence in sentences:\n",
    "            sentences_speeches.append(sentence)\n",
    "\n",
    "    sentence_results = model.predict_sentiment(sentences_speeches)\n",
    "        \n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    sentiment_per_sentence.append(sentence_results) \n",
    "    '''\n",
    "    pos_results.extend([prob[0][1] for prob in result[1]])\n",
    "    neg_results.extend([prob[1][1] for prob in result[1]])\n",
    "    neut_results.extend([prob[2][1] for prob in result[1]])\n",
    "    major_class.extend(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cbb413-7334-499c-9b11-ee7c7e09d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ceb876-ab55-4963-be72-7276d6fe9f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9721f2-b5e8-4594-beeb-44b759532fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla = df_parla.with_columns(pl.Series(name=\"sent_pos\", values=pos_results)) \n",
    "df_parla = df_parla.with_columns(pl.Series(name=\"sent_neg\", values=neg_results)) \n",
    "df_parla = df_parla.with_columns(pl.Series(name=\"sent_neu\", values=neut_results)) \n",
    "df_parla = df_parla.with_columns(pl.Series(name=\"sent_pred\", values=major_class)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12171c-ae42-4d3c-a561-167f39489814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76d590-108b-4131-8786-af8f9f1b2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_parla.write_parquet(\"ParlaMind_sentiment.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9dab1-210e-41bd-8c0b-5effd68d2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df_parla = pl.read_parquet(\"ParlaMind_sentiment.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd04b49-3799-4e3f-9920-f07766b3099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_parla.filter(df_parla[\"speechContent\"].str.len_chars() >= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697140c-1ef7-405f-98f5-b3f7b5725b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef643b-bf6b-4355-811f-fdbf155b2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = (\n",
    "    filtered_df\n",
    "    .group_by([\"abbreviation\", \"sent_pred\"])\n",
    "    .len()\n",
    "    .rename({\"len\": \"count\"})\n",
    ")\n",
    "\n",
    "total_counts = (\n",
    "    filtered_df\n",
    "    .group_by(\"abbreviation\")\n",
    "    .len()\n",
    "    .rename({\"len\": \"total\"})\n",
    ")\n",
    "\n",
    "result = (\n",
    "    sentiment_counts\n",
    "    .join(total_counts, on=\"abbreviation\")\n",
    "    .with_columns((pl.col(\"count\") / pl.col(\"total\") * 100).alias(\"percentage\"))\n",
    "    .pivot(values=\"percentage\", index=\"abbreviation\", columns=\"sent_pred\")\n",
    "    .fill_null(0)  # Fill missing values with 0 if a party has no posts for a sentiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7da05-05c5-4cb4-8372-86472b8e0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7657de-d8e3-46b0-83bb-91c997137f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.sort(\"positive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899038d6-aa1e-4d06-8121-deb11f478b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4af1c-c1b7-4598-b041-aa9d3df9664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8765b37-c20f-4c2a-a935-62ce67104191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date_parsed\")\n",
    ").with_columns(\n",
    "    pl.col(\"date_parsed\").dt.year().alias(\"year\")\n",
    ")\n",
    "\n",
    "df_sentiment_year = df.group_by([\"year\", \"sent_pred\"]).agg(\n",
    "    pl.len().alias(\"sentiment_count\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ff50a-23c9-4c30-bb54-9c8a70d95504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_year = df_sentiment_year.sort(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5f36d-f2cf-410b-9a1a-9db95d151a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(df_sentiment_year, x=\"year\", y=\"sentiment_count\", color='sent_pred')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8b680-0a99-445f-b0b9-8fb2dcda29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e7b21-5187-4f1c-835a-1207ad1a9ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Read data\n",
    "#df_parla = pl.read_parquet(\"br_sentiment.parquet\")\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\", disable=[\n",
    "    \"ner\",\n",
    "    \"lemmatizer\",\n",
    "    \"attribute_ruler\",\n",
    "    \"tagger\",\n",
    "    \"morphologizer\"\n",
    "])\n",
    "\n",
    "def process_batch(speeches_batch):\n",
    "    docs = nlp.pipe(\n",
    "        speeches_batch,\n",
    "        n_process=-1,  \n",
    "    )\n",
    "    return [[sent.text for sent in doc.sents] for doc in docs]\n",
    "\n",
    "batch_size = 4096  \n",
    "data_num = df_parla.height\n",
    "\n",
    "sentences_results = [None] * data_num\n",
    "\n",
    "for start_batch in tqdm(range(0, data_num, batch_size), desc=\"Processing Batches\"):\n",
    "    end_batch = min(start_batch + batch_size, data_num)\n",
    "    \n",
    "    df_batch = df_parla.slice(start_batch, end_batch - start_batch)\n",
    "    speeches_batch = df_batch[\"speechContent\"].to_list()\n",
    "    \n",
    "    batch_sentences = process_batch(speeches_batch)\n",
    "    \n",
    "    sentences_results[start_batch:end_batch] = batch_sentences\n",
    "    \n",
    "\n",
    "df_parla = df_parla.with_columns(pl.Series(\"sentences\", sentences_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad8a7a-c67a-43cf-8351-d9cf1a78c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee45f14-61cf-48d0-a54f-e4950506cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_parla.write_parquet(\"ParlaMind_sentiment_sentence_split.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68e658-c7c9-4a7d-bfd1-8e13b037f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "#df_parla = pl.read_parquet(\"br_sentiment_sentence_split.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67f0b3-cbf7-4afd-86c4-1c9aa958f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ee8ea-b4b2-419d-a3aa-bfbb43b7ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model = SentimentModel()\n",
    "\n",
    "batch_size = 512\n",
    "data_num = df_parla.height\n",
    "\n",
    "pos_results, neg_results, neut_results, major_class = [], [], [], []\n",
    "sentences_predictions = []  \n",
    "\n",
    "for start_batch in tqdm(range(0, data_num, batch_size), desc=\"Processing Batches\"):\n",
    "    df_batch = df_parla.slice(start_batch, batch_size)\n",
    "    \n",
    "    for sentences in df_batch[\"sentences\"]:\n",
    "        if len(sentences) > 1:\n",
    "            result_sentences = model.predict_sentiment(sentences, output_probabilities=False)\n",
    "            sentences_predictions.append(result_sentences)\n",
    "        else:\n",
    "            sentences_predictions.append([])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "df_parla = df_parla.with_columns([\n",
    "    pl.Series(\"sentences_sentiment\", sentences_predictions)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ac97a-8f0b-494c-a910-72af318db27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451968ff-89e8-4872-8656-594dc7c97939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla.write_parquet(\"ParlaMind_all.parquet\") # this is needed for sentiment_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5c466-8cc6-4b1f-b8ab-d171c97e2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82c4cf-bd2a-442c-af03-02475cd3f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "df_parla = pl.read_parquet(\"br_sentiment.parquet\")\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\", disable=[\n",
    "    \"ner\",\n",
    "    \"lemmatizer\",\n",
    "    \"attribute_ruler\",\n",
    "    \"tagger\",\n",
    "    \"morphologizer\"\n",
    "])\n",
    "\n",
    "def process_batch(speeches_batch):\n",
    "    docs = nlp.pipe(\n",
    "        speeches_batch,\n",
    "        n_process=-1,  \n",
    "    )\n",
    "    return [[sent.text for sent in doc.sents] for doc in docs]\n",
    "\n",
    "batch_size = 4096  \n",
    "data_num = df_parla.height\n",
    "\n",
    "sentences_results = [None] * data_num\n",
    "\n",
    "for start_batch in tqdm(range(0, data_num, batch_size), desc=\"Processing Batches\"):\n",
    "    end_batch = min(start_batch + batch_size, data_num)\n",
    "    \n",
    "    df_batch = df_parla.slice(start_batch, end_batch - start_batch)\n",
    "    speeches_batch = df_batch[\"speechContent\"].to_list()\n",
    "    \n",
    "    batch_sentences = process_batch(speeches_batch)\n",
    "    \n",
    "    sentences_results[start_batch:end_batch] = batch_sentences\n",
    "    \n",
    "\n",
    "df_parla = df_parla.with_columns(pl.Series(\"sentences\", sentences_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33a399-2c47-48cc-8c0e-036014d58ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla_top = pl.read_parquet(\"top.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddf436-7134-4fe8-bb77-fd563c9d9289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd4883-4fb1-4ec2-b711-0bc347e91b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "neu_list = []\n",
    "neg_list = []\n",
    "for sentence_sentiment in df_parla_top.select(\"sentences_sentiment\").to_series():\n",
    "    pos = 0\n",
    "    neu = 0\n",
    "    neg = 0\n",
    "    for sentiment in sentence_sentiment:\n",
    "        if sentiment == \"positive\":\n",
    "            pos += 1\n",
    "        elif sentiment == \"neutral\":\n",
    "            neu += 1\n",
    "        elif sentiment == \"negative\":\n",
    "            neg += 1\n",
    "\n",
    "    pos_list.append(pos)\n",
    "    neu_list.append(neu)\n",
    "    neg_list.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6d3b8-6d6d-4764-ba89-b4f4f1678ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla_top = df_parla_top.with_columns(pl.Series(name=\"pos_per_sentence\", values=pos_list)) \n",
    "df_parla_top = df_parla_top.with_columns(pl.Series(name=\"neg_per_sentence\", values=neg_list)) \n",
    "df_parla_top = df_parla_top.with_columns(pl.Series(name=\"neu_per_sentence\", values=neu_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89b7c4-3bd4-4382-87b1-721e4ece64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla_top = df_parla_top.filter(df_parla_top[\"speechContent\"].str.len_chars() >= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c43b2-d591-4d22-93f1-3e7da85e926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_parla_top.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date_parsed\")\n",
    ").with_columns(\n",
    "    pl.col(\"date_parsed\").dt.year().alias(\"year\")\n",
    ")\n",
    "\n",
    "df_parla_top_year = df.group_by([\"year\", \"pos_per_sentence\", \"neg_per_sentence\", \"neu_per_sentence\"]).agg(\n",
    "    pl.len().alias(\"sentiment_count\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7fa02-c649-47ca-b970-19e9803f1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla_top_year = df_parla_top_year.sort(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa138596-348b-46e0-9051-3986bf793221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parla_top_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce341a4c-7487-4cfd-8c77-c693b0fc366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_sum = df_parla_top_year.group_by(\"year\").agg([\n",
    "    pl.col(\"pos_per_sentence\").sum(),\n",
    "    pl.col(\"neg_per_sentence\").sum(),\n",
    "    pl.col(\"neu_per_sentence\").sum()\n",
    "]).sort(\"year\")\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['pos_per_sentence'],\n",
    "                        name='Positive'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['neg_per_sentence'],\n",
    "                        name='Negative'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['neu_per_sentence'],\n",
    "                        name='Neutral'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentiment Analyse pro Jahr',\n",
    "    xaxis_title='Jahr',\n",
    "    yaxis_title='Summe der Sentiments',\n",
    "    legend_title='Sentiment Typ'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5bbf10-a0b1-40b0-8e16-3f0aa5875153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df_parla_top = pl.read_parquet(\"top.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5326c6-67ba-4569-9ecb-85e4395c437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = df_parla_top.select(\"speechContent\").to_series().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b1863-9c06-4620-b4d8-72695da578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Bereinigt einen Text durch verschiedene Vorverarbeitungsschritte\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def remove_stopwords(text, custom_stopwords=None):\n",
    "    \"\"\"\n",
    "    Entfernt Stoppwörter aus dem Text\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    \n",
    "    if custom_stopwords:\n",
    "        stop_words.update(custom_stopwords)\n",
    "    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Führt Lemmatisierung durch (Grundform der Wörter)\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text\n",
    "\n",
    "def preprocess_political_speeches(speeches, custom_stopwords=None):\n",
    "    processed_speeches = []\n",
    "    \n",
    "    for speech in tqdm(speeches, desc=\"Processing speeches\", unit=\"speech\"):\n",
    "        cleaned_text = clean_text(speech)\n",
    "        \n",
    "        text_without_stopwords = remove_stopwords(cleaned_text, custom_stopwords)\n",
    "        \n",
    "        lemmatized_text = lemmatize_text(text_without_stopwords)\n",
    "        \n",
    "        processed_speeches.append(lemmatized_text)\n",
    "    \n",
    "    return processed_speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12199f-b7b1-4df6-b839-1bea133b9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_speeches = preprocess_political_speeches(speeches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf88962-8bda-4686-a59e-50dcc0d96959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(processed_speeches)\n",
    "\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ee577-ca59-45f7-8f9e-fb76bd138900",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01115c7b-7063-43d9-80b3-3a27460d06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedfec5-db8b-4140-b0a4-d56b704b9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509cf1ff-75f0-41ae-b5e8-1cdcc9edc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a136e8-aba4-4422-82ef-a4a3c45acb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"bundeswehr\", top_n=5)\n",
    "topic_model.get_topic(similar_topics[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef00a0-2304-4ba5-b454-ff31d499e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.save(\"topic_model\", serialization=\"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004dc9e-421d-4f43-b760-a2aca641b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(\"top_cleanded_Sentences.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ff0ef-695f-4ff7-9703-f4a227a4106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b59f7-b07b-498e-9588-33bad6fab9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "\n",
    "loaded_model = BERTopic.load(\"topic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85286983-8479-46a0-9f57-e11d06f5c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(\"top_cleanded_Sentences.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d567b2-6d0f-4dd5-aea5-fed4b75f693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"cleanded_sentence\").len() > 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0f1b0-eaa8-4b49-91ee-e0ee2359776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629f56f-fb80-4d40-818b-bd67c358b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"date_parsed\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2308d0-bec9-46db-bf30-7990f04b9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "timestamps = df.select(\"date_parsed\").to_series().to_list()\n",
    "timestamps_np = np.array(timestamps, dtype='datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f90f6-0f0c-410e-8033-d0bd8bfb1267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_over_time = loaded_model.topics_over_time(df.select(\"cleanded_sentence\").to_series().to_list(), timestamps_np, nr_bins=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a9e58-6f08-4b38-a389-763ead8c445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timon = pl.read_parquet(\"processed_bundestags_daten.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989bb97-1ca1-4f7a-91a3-de47e6b4fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d25d03-d704-48ac-8dac-02ae3844dcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141ad86-69ed-4457-bb52-a01db3d7ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_sum = df_timon.group_by(\"year\").agg([\n",
    "    pl.col(\"pos\").sum(),\n",
    "    pl.col(\"neg_per_sentence\").sum(),\n",
    "    pl.col(\"neu_per_sentence\").sum()\n",
    "]).sort(\"year\")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['pos_per_sentence'],\n",
    "                        name='Positive'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['neg_per_sentence'],\n",
    "                        name='Negative'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_yearly_sum['year'], \n",
    "                        y=df_yearly_sum['neu_per_sentence'],\n",
    "                        name='Neutral'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sentiment Analyse pro Jahr',\n",
    "    xaxis_title='Jahr',\n",
    "    yaxis_title='Summe der Sentiments',\n",
    "    legend_title='Sentiment Typ'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
